{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Composite Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Composite Transformers** in scikit-learn are transformers that allow you to combine multiple transformation steps into a single unit, making it easier to manage complex data preprocessing workflows. This can be done by using various techniques such as pipelines or specific composite transformers like `FeatureUnion` or `ColumnTransformer`.\n",
    "\n",
    "Here’s a breakdown of the most common composite transformers and how to use them:\n",
    "\n",
    "### 1. **Pipeline**\n",
    "\n",
    "The **Pipeline** is a linear sequence of transformers followed by an estimator. This is the most basic way to chain multiple transformers together and ensure that each step's output is passed as input to the next step. It's a common method for combining preprocessing and modeling.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a pipeline that standardizes the data and then applies logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),    # Step 1: Scale the features\n",
    "    ('classifier', LogisticRegression())  # Step 2: Fit logistic regression model\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the pipeline\n",
    "predictions = pipeline.predict(X_test)\n",
    "```\n",
    "\n",
    "### 2. **FeatureUnion**\n",
    "\n",
    "The **FeatureUnion** allows you to apply multiple transformers in parallel to the same dataset and concatenate their results. This is useful when you want to apply different transformations to the same data and combine their outputs.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define individual transformers\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Combine them using FeatureUnion\n",
    "combined_transformer = FeatureUnion([\n",
    "    ('scaler', scaler),  # Standardize the features\n",
    "    ('pca', pca)         # Apply PCA for dimensionality reduction\n",
    "])\n",
    "\n",
    "# Apply the combined transformations\n",
    "X_transformed = combined_transformer.fit_transform(X)\n",
    "```\n",
    "\n",
    "In this case, the data will first be scaled and then reduced using PCA, with both the scaled and reduced data being concatenated into a single output.\n",
    "\n",
    "### 3. **ColumnTransformer**\n",
    "\n",
    "The **ColumnTransformer** allows you to apply different transformations to different columns (features) of your dataset. This is especially useful when dealing with datasets that contain both numerical and categorical features, where each type of feature might need different preprocessing.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define transformations for different types of columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [0, 1, 2]),  # Apply StandardScaler to numerical columns\n",
    "        ('cat', OneHotEncoder(), [3])          # Apply OneHotEncoder to categorical column\n",
    "    ])\n",
    "\n",
    "# Apply the ColumnTransformer\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "```\n",
    "\n",
    "Here:\n",
    "- Columns 0, 1, and 2 are numerical features that will be scaled using `StandardScaler`.\n",
    "- Column 3 is a categorical feature that will be one-hot encoded using `OneHotEncoder`.\n",
    "\n",
    "### 4. **Combining Pipelines and ColumnTransformer**\n",
    "\n",
    "You can also nest pipelines inside a `ColumnTransformer` or use `FeatureUnion` inside pipelines, making it easier to create complex data preprocessing workflows.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())  # Scale numerical data\n",
    "])\n",
    "\n",
    "# Define categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder())  # One-hot encode categorical data\n",
    "])\n",
    "\n",
    "# Combine the pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, [0, 1, 2]),  # Apply num_pipeline to numerical columns\n",
    "    ('cat', cat_pipeline, [3])         # Apply cat_pipeline to categorical columns\n",
    "])\n",
    "\n",
    "# Combine preprocessing with a classifier in a final pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),   # Preprocess the data\n",
    "    ('classifier', LogisticRegression())  # Fit logistic regression\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the model\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "### Summary of Composite Transformers:\n",
    "\n",
    "1. **Pipeline:** Chains multiple steps together in sequence, ensuring each step’s output is passed to the next step. Useful for preprocessing and model fitting in one workflow.\n",
    "   \n",
    "2. **FeatureUnion:** Combines multiple transformers in parallel, allowing their outputs to be concatenated. Useful for applying different transformations to the same data in parallel.\n",
    "\n",
    "3. **ColumnTransformer:** Applies different transformations to different subsets of the data (columns). Ideal for datasets with both numerical and categorical features that require different preprocessing.\n",
    "\n",
    "4. **Combining Pipelines:** You can nest pipelines inside `ColumnTransformer` or other composite transformers, creating flexible, layered workflows.\n",
    "\n",
    "Each of these composite transformers allows for flexible, reusable, and scalable preprocessing pipelines that fit seamlessly into the scikit-learn ecosystem. Let me know if you need more examples or specific help with composite transformers!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
